{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trend with Tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "# pip install ISStreamer\n",
    "from ISStreamer.Streamer import Streamer\n",
    "from textwrap import TextWrapper\n",
    "from datetime import datetime\n",
    "from elasticsearch import Elasticsearch\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api_1\n",
    "c_key = \"cqBrLtGgcmMOVVujAhYH74sAD\"\n",
    "c_secret = \"Kh3TjMUXXfEP2iZmJVCavjEpxWLr5yz93abe6alNejpeiVV4WY\"\n",
    "a_token = \"403109204-fsqizf8LQPiW5edNFrBqNXOKee4beUn0bUJeK3qx\"\n",
    "a_token_secret = \"4BXdQDvl9eiKDaGlAPiQW8811NU80jLMVvwWHO4z9URDE\"\n",
    "\n",
    "tweepy_auth = tweepy.OAuthHandler(c_key, c_secret)\n",
    "tweepy_auth.set_access_token(a_token,a_token_secret)\n",
    "tweepy_api = tweepy.API(tweepy_auth, timeout=3000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api_2\n",
    "c_key2 = \"eVsSW7yWRBqle5VeiLgMP3ufC\"\n",
    "c_secret2 = \"TmReOPxOFm754hcCRTmjBsVXRDnvecZetf4N862fUDwMnPJyOr\"\n",
    "a_token2 = \"1333282740104400897-J7ypSnwUoKbQ5L6BXpSlK6zMNThnsh\"\n",
    "a_token_secret2 = \"T7S24JJCoV5JeHJDVYEnHfGhzNZBY4KvWkVUfylyVfCs0\"\n",
    "\n",
    "tweepy_auth2 = tweepy.OAuthHandler(c_key2, c_secret2)\n",
    "tweepy_auth2.set_access_token(a_token2,a_token_secret2)\n",
    "tweepy_api2 = tweepy.API(tweepy_auth2, timeout=3000000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Location csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>country</th>\n",
       "      <th>WOEID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AE</td>\n",
       "      <td>24.4781</td>\n",
       "      <td>54.3686</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>1940330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AR</td>\n",
       "      <td>-34.5997</td>\n",
       "      <td>-58.3819</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>23424747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT</td>\n",
       "      <td>48.2083</td>\n",
       "      <td>16.3731</td>\n",
       "      <td>Austria</td>\n",
       "      <td>23424750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AU</td>\n",
       "      <td>-35.2931</td>\n",
       "      <td>149.1269</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1099805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BE</td>\n",
       "      <td>50.8467</td>\n",
       "      <td>4.3517</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>23424757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code      lat       lng               country     WOEID\n",
       "0   AE  24.4781   54.3686  United Arab Emirates   1940330\n",
       "1   AR -34.5997  -58.3819             Argentina  23424747\n",
       "2   AT  48.2083   16.3731               Austria  23424750\n",
       "3   AU -35.2931  149.1269             Australia   1099805\n",
       "4   BE  50.8467    4.3517               Belgium  23424757"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_csv = pd.read_csv('location.csv')\n",
    "del location_csv['Unnamed: 5']\n",
    "del location_csv['Unnamed: 6']\n",
    "\n",
    "location_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. ElasticSearch Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpop_list = ['bts', '방탄', 'jimin', '슈가', '제이홉', '뷔', '정국', 'suga', 'taehyung'\n",
    "             'jungkook', 'bighit', 'dynamite', 'fakelove', 'jhope', 'hobi', '호석', '호비', \n",
    "            'blackpink', 'jisoo', 'killthislove', 'lovesickgirls', 'Rosé', '블랙핑크', \n",
    "             '블핑', '제니', '리사', '로제', '지수', 'howyoulikethat', 'kpop', '카이', '엑소',\n",
    "            'exo', '백현', 'baekhyun', 'suho', 'chanyeol', 'sehun', 'xiumin', '시우민', '찬열']\n",
    "\n",
    "es = Elasticsearch('3.238.129.195:9200')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. filter X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch('localhost:9200')\n",
    "trend_dict = {}\n",
    "\n",
    "for i in range(len(location_csv)): # csv 내의 모든 location\n",
    "    \n",
    "    woeid = location_csv.iloc[i]['WOEID']\n",
    "    \n",
    "    # 해당 location의 trend 불러오기\n",
    "    trends = tweepy_api.trends_place(woeid)\n",
    "    trends = trends[0]\n",
    "   \n",
    "    # 해당 location의 위도, 경도 불러오기\n",
    "    lat = location_csv.iloc[i]['lat']\n",
    "    lng = location_csv.iloc[i]['lng']\n",
    "\n",
    "    # coordinate 형식으로 만들기\n",
    "    coor = {}\n",
    "    coor[\"coordinates\"] = [lng, lat]\n",
    "    coor[\"type\"] = \"Point\"   \n",
    "    \n",
    "    trends['coordinates'] = coor\n",
    "    trends['locations'] = trends['locations'][0]\n",
    "\n",
    "    for k in range(len(trends['trends'])): # 여러 개의 trend 쪼개서 elasticsearch로 넘기기\n",
    "        push_trend['trends'] = trends['trends'][k]\n",
    "        push_trend['as_of'] = trends['as_of']\n",
    "        push_trend['created_at'] = trends['created_at']\n",
    "        push_trend['locations'] = trends['locations']\n",
    "        push_trend['coordinates'] = trends['coordinates']     \n",
    "\n",
    "        es.index(index=\"trend\", doc_type=\"twitter_trend\", body=push_trend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. filter O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_dict = {}\n",
    "\n",
    "for i in range(len(location_csv)): # csv 내의 모든 location\n",
    "    \n",
    "    woeid = location_csv.iloc[i]['WOEID']\n",
    "\n",
    "    # 해당 location의 trend 불러오기\n",
    "    trends = tweepy_api2.trends_place(woeid)\n",
    "    trends = trends[0]\n",
    "   \n",
    "    # 해당 location의 위도, 경도 불러오기\n",
    "    lat = location_csv.iloc[i]['lat']\n",
    "    lng = location_csv.iloc[i]['lng']\n",
    "\n",
    "    # coordinate 형식으로 만들기\n",
    "    coor = {}\n",
    "    coor[\"coordinates\"] = [lng, lat]\n",
    "    coor[\"type\"] = \"geo_point\"   \n",
    "    \n",
    "    trends['coordinates'] = coor\n",
    "    trends['locations'] = trends['locations'][0]\n",
    "\n",
    "    for k in range(len(trends['trends'])): # 여러 개의 trend 쪼개서 elasticsearch로 넘기기\n",
    "        \n",
    "        # kpop_list의 단어가 포함되었는지 확인\n",
    "        num = 0\n",
    "        for word in kpop_list:\n",
    "            if (word in trends['trends'][k]['name'].lower()):\n",
    "                num += 1\n",
    "        \n",
    "        # 포함되었다면 elasticsearch로 넘기기\n",
    "        if (num > 0):\n",
    "            push_trend['trends'] = trends['trends'][k]\n",
    "            push_trend['as_of'] = trends['as_of']\n",
    "            push_trend['created_at'] = trends['created_at']\n",
    "            push_trend['locations'] = trends['locations']\n",
    "            push_trend['coordinates'] = trends['coordinates']     \n",
    "\n",
    "            es.index(index=\"trend\", doc_type=\"twitter_trend\", body=push_trend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Mapping for geo_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mapping 시도 !\n",
    "위에는 자동 mapping으로 실행한 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.elastic.co/guide/en/elasticsearch/reference/6.1/geo-point.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'trend_final'}"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mappings = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"trends\": {\n",
    "                \"properties\":{\n",
    "                    \"name\": {\"type\":\"text\"},\n",
    "                    \"url\":{\"type\" : \"text\"},\n",
    "                    \"promoted_content\":{\"type\" : \"text\"},\n",
    "                    \"query\":{\"type\" : \"text\"},\n",
    "                    \"tweet_volume\":{\"type\":\"long\"} \n",
    "                }\n",
    "\n",
    "             },\n",
    "            \"as_of\": {\"type\":\"date\"},\n",
    "            \"created_at\": {\"type\":\"date\"},\n",
    "            \"locations\": {\n",
    "                \"properties\":{\n",
    "                    \"name\":{\"type\":\"text\"},\n",
    "                    \"woeid\":{\"type\":\"long\"}\n",
    "                }\n",
    "             },\n",
    "            \"coordinates\": {\"type\":\"geo_point\"}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "es.indices.create(index='trend_final', body=mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_dict = {}\n",
    "\n",
    "for i in range(len(location_csv)): # csv 내의 모든 location\n",
    "    \n",
    "    woeid = location_csv.iloc[i]['WOEID']\n",
    "\n",
    "    # 해당 location의 trend 불러오기\n",
    "    trends = tweepy_api.trends_place(woeid)\n",
    "    trends = trends[0]\n",
    "   \n",
    "    # 해당 location의 위도, 경도 불러오기\n",
    "    lat = location_csv.iloc[i]['lat']\n",
    "    lng = location_csv.iloc[i]['lng']\n",
    "\n",
    "    # coordinate 형식으로 만들기\n",
    "    coor = {}\n",
    "    coor['lon'] = lng\n",
    "    coor['lat'] = lat\n",
    "\n",
    "    trends['coordinates'] = coor\n",
    "    trends['locations'] = trends['locations'][0]\n",
    "\n",
    "    for k in range(len(trends['trends'])): # 여러 개의 trend 쪼개서 elasticsearch로 넘기기\n",
    "        \n",
    "        # kpop_list의 단어가 포함되었는지 확인\n",
    "        num = 0\n",
    "        for word in kpop_list:\n",
    "            if (word in trends['trends'][k]['name'].lower()):\n",
    "                num += 1\n",
    "        \n",
    "        # 포함되었다면 elasticsearch로 넘기기\n",
    "        if (num > 0):\n",
    "            push_trend['trends'] = trends['trends'][k]\n",
    "            push_trend['as_of'] = trends['as_of']\n",
    "            push_trend['created_at'] = trends['created_at']\n",
    "            push_trend['locations'] = trends['locations']\n",
    "            push_trend['coordinates'] = trends['coordinates']     \n",
    "\n",
    "            es.index(index=\"trend_final\", body=push_trend)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
